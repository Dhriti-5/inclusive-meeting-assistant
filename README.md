
# **Inclusive Meeting Assistant** ğŸ™ğŸ¤

An AI-powered assistant that makes meetings more **accessible and inclusive**, inspired by [Read.ai](https://read.ai).  
This project integrates **speech recognition, summarization, action item extraction, translation, text-to-speech, email export, speaker diarization, and automated meeting bot** into a unified pipeline.

---

## **âœ¨ Features Implemented**

### **1. ğŸ¤ Speech to Text (ASR)**
- Converts meeting audio into text using **OpenAI Whisper** or ASR pipeline.
- **Input:** Recorded audio from `speech_Module`  
- **Output:** `output/transcript.txt`

### **2. ğŸ“ Meeting Summarization**
- Summarizes long transcripts into concise notes
- Powered by **HuggingFace Transformers** (`distilbart-cnn-12-6`)
- Example: 10-minute transcript â†’ 4â€“5 sentence summary

### **3. âœ… Action Items Extraction**
- Extracts decisions, todos, and next steps from meeting notes
- Powered by **Google FLAN-T5**
- Returns **bullet-point action items**

### **4. ğŸŒ Multilingual Translation**
- Translates transcripts or summaries into multiple languages
- Uses **Helsinki-NLP MarianMT models**
- Example: `en â†’ hi`, `en â†’ fr`, etc.

### **5. ğŸ”Š Text to Speech (TTS)**
- Converts meeting summaries or action items into speech audio
- Uses **pyttsx3** for offline TTS
- **Output:** `.wav` audio file for recap

### **6. ğŸ“§ Email Export**
- Exports meeting notes & action items to email
- SMTP integration (tested; DNS issues pending fix)
- Sends summaries directly to participants

### **7. ğŸ§‘â€ğŸ¤â€ğŸ§‘ Speaker Diarization**
- Identifies **who spoke when** during the meeting
- Implemented with **pyannote.audio** diarization pipeline
- **Output:** Timestamps with speaker labels (`SPEAKER_00`, `SPEAKER_01`, â€¦)
- **Next:** Merge diarization with transcripts â†’ speaker-attributed summaries

### **8. âš¡ Real-Time WebSocket Updates (Phase 3)**
- **Problem:** Eliminated inefficient polling (60 requests/minute)
- **Solution:** WebSocket connections for instant updates
- **Benefits:**
  - 97% reduction in network requests
  - 20x faster updates (<100ms vs 0-2000ms)
  - Real-time processing status (diarization, transcription, alignment)
  - Auto-reconnection with exponential backoff
- **Implementation:**
  - Backend: WebSocket manager + broadcasting during audio processing
  - Frontend: Custom `useWebSocket` React hook
  - Connection status indicator in UI
- **See:** `PHASE3_SUMMARY.md`, `PHASE3_QUICKSTART.md` for details

### **9. ğŸ¤– Automated Meeting Bot (Phase 4) - THE KILLER FEATURE**
- **Problem:** Manual meeting joining and transcription setup
- **Solution:** Automated bot that joins Google Meet and captures audio
- **Features:**
  - âœ… Automated Google Meet joining (Puppeteer)
  - âœ… Real-time audio capture (puppeteer-stream)
  - âœ… Live transcription streaming (Whisper + WebSocket)
  - âœ… Browser automation with intelligent join detection
  - âœ… Headless/visible mode for debugging
- **Architecture:**
  - Bot Engine (Node.js) â†’ Audio Capture â†’ WebSocket â†’ Backend (Python)
  - Backend processes audio with Whisper â†’ Broadcasts to Frontend
  - Seamless integration with Phase 3 WebSocket infrastructure
- **Usage:**
  ```bash
  cd bot_engine
  npm install
  npm start
  ```
- **See:** `PHASE4_QUICKSTART.md`, `bot_engine/README.md` for complete guide

---

## **ğŸ— Project Structure**

```
inclusive-meeting-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI entrypoint + WebSocket endpoints
â”‚   â”œâ”€â”€ bot_audio_processor.py   # Bot audio processing & Whisper integration
â”‚   â”œâ”€â”€ websocket_manager.py     # WebSocket connection management
â”‚   â”œâ”€â”€ pipeline_runner.py       # Orchestrates NLP pipeline
â”‚   â”œâ”€â”€ nlp_module/
â”‚   â”‚   â”œâ”€â”€ nlp_pipeline.py      # Summarization, Action items, Translation
â”‚   â”‚   â”œâ”€â”€ translate_text.py
â”‚   â”œâ”€â”€ speech_Module/           # Whisper / ASR integration
â”‚   â”œâ”€â”€ sign_Module/             # Sign language detection
â”‚   â”œâ”€â”€ tts_Module/
â”‚   â”‚   â”œâ”€â”€ text_to_speech.py
â”‚   â”œâ”€â”€ speaker_diarization.py   # Pyannote diarization pipeline
â”‚   â””â”€â”€ output/                  # Transcripts, summaries, etc.
â”‚
â”œâ”€â”€ bot_engine/                  # Meeting Bot (Phase 4)
â”‚   â”œâ”€â”€ bot_engine.js            # Puppeteer automation + audio capture
â”‚   â”œâ”€â”€ package.json             # Node.js dependencies
â”‚   â”œâ”€â”€ .env.example             # Configuration template
â”‚   â””â”€â”€ README.md                # Bot setup guide
â”‚
â”œâ”€â”€ frontend/                    # React.js (UI for meetings)
â”œâ”€â”€ test_all_features.py         # Test script to verify all features
â”œâ”€â”€ test_bot_audio.py            # Bot audio processing tests
â”œâ”€â”€ setup_bot.bat / .sh          # Bot setup scripts
â”œâ”€â”€ start_bot.bat / .sh          # Bot start scripts
â””â”€â”€ README.md
```

---

## **âš™ï¸ Installation & Setup**

### **1. Clone Repository**
```bash
git clone https://github.com/yourusername/inclusive-meeting-assistant.git
cd inclusive-meeting-assistant
```

### **2. Create Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate    # Linux/Mac
venv\Scripts\activate       # Windows
```

### **3. Install Dependencies**
```bash
pip install -r requirements.txt
```

**Required Libraries:**
- `transformers`
- `torch`
- `pyttsx3`
- `speechbrain`
- `pyannote.audio`
- `openai-whisper`
- `fastapi`, `uvicorn`
- `mediapipe`, `opencv-python`
- `tensorflow` / `tflite-runtime`

### **4. Set HuggingFace Token**
```bash
setx HUGGINGFACE_TOKEN "hf_xxx..."
```

### **5. Run Backend**
```bash
cd backend
uvicorn main:app --reload
```

### **6. Run Test Script**
```bash
python test_all_features.py
```

---

## **ğŸ—º Roadmap & Completed Phases**

### **âœ… Completed**
- **Phase 1:** Core NLP features (summarization, action items, translation, TTS)
- **Phase 2:** MongoDB + JWT Authentication
- **Phase 3:** WebSocket real-time updates
- **Phase 4:** Automated Meeting Bot ğŸ‰

### **ğŸ”œ Upcoming**
- **Phase 5:** Client-side sign language detection (in development)
- **Phase 6:** Full frontend integration with authentication
- **Phase 7:** Collaborative features (multi-user editing)
- **Phase 8:** Support for Zoom, Microsoft Teams
- Merge diarization output with transcript â†’ **speaker-attributed summaries**
- Topic segmentation â†’ break meetings into themes
- Export options (PDF, Notion, etc.)
- Browser extension (Zoom / Meet integration)
- Real-time dashboard with speaker labels
